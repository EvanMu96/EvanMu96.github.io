<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Komoriii</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Komoriii">
<meta property="og:url" content="http://blog.senevan.com/page/2/index.html">
<meta property="og:site_name" content="Komoriii">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Komoriii">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Komoriii" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Komoriii</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/About-Me">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS 订阅"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://blog.senevan.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-2020-02-08" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/02/08/2020-02-08/" class="article-date">
  <time class="dt-published" datetime="2020-02-08T12:19:17.000Z" itemprop="datePublished">2020-02-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/02/08/2020-02-08/">[最近的日常] vol.0</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>最近在干啥这个系列主要讲讲最近做了什么有意思的事情。流水账偏多。<br>闪2也打完了。如果我没有玩过闪4的话，我相信闪2会对我带来更好的体验。2代最明显的缺陷还是为了推游戏系统把剧情牺牲了，把内战描写硬生生搞成了回合制：找VII班同学，找其他同学，行动解放某地。2代我起手一周目选择了nightmare难度，难度还好，除了克罗斯贝尔的外传部分被黎爷一个疾风两人一起残血。<br>至此，闪之轨迹I II III IV都已经破关。白金的话会从闪3开始，3周目应该能白金（二周目漏了广播话题和不知道哪个宝箱）。<br>———分割线————-<br>这段时间在家打通了闪之轨迹134。在打通1代之后去查了一下，2貌似质量有点不是那么高就直接从1跳到了3。3还是非常好玩的，我连着打的所以并不会因为3的结尾突兀而想骂街。</p>
<p>![英雄傳說 閃之軌跡Ⅲ_20200125160131](/images/英雄傳說 閃之軌跡Ⅲ_20200125160131.jpg)</p>
<p>闪4的???路线大结局真好啊，黎爷他笑容逐渐消失之后终于笑了。</p>
<p>![英雄傳說 閃之軌跡Ⅳ -THE END OF SAGA-_20200207193621](/images/英雄傳說 閃之軌跡Ⅳ -THE END OF SAGA-_20200207193621.jpg)</p>
<p>闪轨1玩的比较咸鱼，有的地方打不过就干脆降低难度了。3代4代玩的时候一周目normal不允许自己翻车降难度，不过3代的破防硬直太长，破防之后只要AT DELAY足够短就可以连到boss再起不能，后面也就没翻车过。4代的话，有时间爆发后游戏难度降低了非常多，魔法攻击的重要性猛增。</p>
<p>今年出《零之轨迹 改》和《碧之轨迹 改》的话试试一周目就选nightmare难度。<br>月初解锁的伊苏9也开始玩了，让人感觉不爽的是伊苏9在城市里的场景掉帧太严重了，明明有些npc连对话都不能要么就删一下让城市的帧数能大部分时间稳60fps也好。伊苏玩的比较慢，我玩8代的时候也是。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.senevan.com/2020/02/08/2020-02-08/" data-id="cklhq789n00094hoo82zy6fsa" data-title="[最近的日常] vol.0" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2020-01-26" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/01/26/2020-01-26/" class="article-date">
  <time class="dt-published" datetime="2020-01-25T16:09:02.000Z" itemprop="datePublished">2020-01-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/01/26/2020-01-26/">[LeetCode] 779. 第K个语法符号</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="题目内容"><a href="#题目内容" class="headerlink" title="题目内容"></a>题目内容</h2><p><i>在第一行我们写上一个 0。接下来的每一行，将前一行中的0替换为01，1替换为10。</p>
<p>给定行数 N 和序数 K，返回第 N 行中第 K个字符。（K从1开始）</i></p>
<p>例子:</p>
<p>输入: N = 1, K = 1<br>输出: 0</p>
<p>输入: N = 2, K = 1<br>输出: 0</p>
<p>输入: N = 2, K = 2<br>输出: 1</p>
<p>输入: N = 4, K = 5<br>输出: 1</p>
<p>解释:<br>第一行: 0<br>第二行: 01<br>第三行: 0110<br>第四行: 01101001</p>
<p>注意：</p>
<p>N 的范围 <code>[1, 30]</code>.<br>K 的范围 <code>[1, 2^(N-1)]</code>.</p>
<p>来源：力扣（LeetCode）<br>链接：<a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/k-th-symbol-in-grammar">https://leetcode-cn.com/problems/k-th-symbol-in-grammar</a><br>著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处</p>
<p>题目链接：<a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/k-th-symbol-in-grammar/">https://leetcode-cn.com/problems/k-th-symbol-in-grammar/</a></p>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><p>我个人的习惯是遇到一个题会默认用暴力的做法做的，但是这道题用生成第N行字符串的方法最多会生成2^(30-1)=1073741824长度的字符串导致超时。</p>
<p>在看了几份答案之后找到了一个可读性好思路清晰，并且可以学到一些通用的思路的解答方法。</p>
<p>首先当N大于2时，这个字符串时对称的，后半段是前半段的取反。</p>
<p>所以递归就可以这么写了。</p>
<p>base 有两个</p>
<ol>
<li>N == 1 只会返回0</li>
<li>N == 2 如果K==1 返回0否则返回1</li>
</ol>
<p>对于第Nth字符串的长度，是2^(N-1)。当K在[ 0, 2^(N- 1) / 2 ]之间时，这个字符串和N-1th的第K个是相同的。而当K在( 2^(N - 1)/ 2, 2^(N - 1) )之间时，这个字符串时和N-1th的第(K - 2^(N-  1) / 2)个相反的，也就是是对折前半部分的关系。</p>
<p>所以代码如下。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">kthGrammar</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">int</span> K)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(N == <span class="number">1</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(N == <span class="number">2</span>) <span class="keyword">return</span> K == <span class="number">1</span> ? <span class="number">0</span> : <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> half = <span class="built_in">pow</span>(<span class="number">2</span>, N - <span class="number">1</span>) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(K &lt;= half)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> kthGrammar(N - <span class="number">1</span>, K);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> - kthGrammar(N - <span class="number">1</span>, K - half);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.senevan.com/2020/01/26/2020-01-26/" data-id="cklhq789m00084hoogoiu69k7" data-title="[LeetCode] 779. 第K个语法符号" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-2019-02-08" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/02/08/2019-02-08/" class="article-date">
  <time class="dt-published" datetime="2019-02-08T14:30:23.000Z" itemprop="datePublished">2019-02-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/02/08/2019-02-08/">[东拼西凑] P and NP</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>嗨。It’s been a while.我又一次重新开始写博客了。我这个人对自己留下的幼稚的痕迹曾经十分厌恶，尤其是半途而废的幼稚痕迹。所以我的博客这次已经是第三次重启了，希望这次我能够做到以后看这些东西不会想着赶紧删掉。电影《寻梦环游记》里讲，人有三次死亡，第三次死亡即使被大家所遗忘。我已经从大学中拿着本科和硕士学位毕业，过几年也会加入奔三的队伍中。是时候在人类社会中，或者是在北冰洋的Github备份中给自己留下几个Byte的位置了。<br>新博客的第一篇文章就是补充一篇上一次重启博客没有完成的学习笔记。笔记里的很多内容是参考了吴军博士的《数学之美》，维基百科和知乎上的解答，在这里感谢他们对P/NP这个未解之谜的解释。<br><b/>下面这段文字来自《数学之美》（作者：吴军博士）的附录，偏向于inituition。</b><br>计算机的算法效率是用计算复杂度(Computational Complexity)来衡量的。计算的时间显然和问题的大小有关。比如对10000个实数排序和对1000000个实数排序所用的时间是显然不同的。问题的大小在衡量计算时间复杂度时是变量，一般用N来表示。而计算量是N的一个函数f(N)。这个函数的边界可以用数学上的大O概念来限制。如果两个函数f(N)和g(N)在大O概念上相同，也就是说当N趋近于无穷大时，他们的比值只差一个常数。比如f(N)=N<em>log(N), g(N)=100</em>log(n)，他们就被看做是同一个数量级的。同样，如果两个计算机算法的计算在大O概念下相同，只差一个常数，我们认为它们的计算复杂度相同。计算的复杂度关键看函数而不是这个常数。<br>如果一个算法的计算量是N的多项式函数(Polynomial Function)，则认为这个算法是多项式函数复杂度的。如果一个问题存在一个多项式函数复杂度的算法，则这个问题成为P问题。如果计算量比N的多项式函数还要高，虽然理论上讲如果有无限的时间也是可以计算的（图灵机概念的可计算），但实际上市不可计算的。这时称为非多项式(NP)问题。比如找到每一步围棋的最佳走法就是一个NP问题。<br>如果一个NP问题，虽然找不到多项式函数复杂度的算法，但是对于一个算法可以再多项式函数复杂度的时间内证实这个方法正确与否。那么这个问题成为NP-Complete问题。如果一个问题，它的计算复杂度至少是NP-Complete，那么它被称作NP-Hard问题。换句话讲NPC问题是NP-Hard问题的一个子集。</p>
<p><b/>以下的文字来源于我对维基百科和知乎上的文章的整理，也补充上了NP-C Problem的介绍。</b><br>P类问题：所有可以在多项式时间内求解的判定问题（返回一个yes/no）构成P类问题。比如验证一个数是否是质数，我们可以从2一直除到这个数本身来验证这个数有没有除了1和本身以外的factor。<br>NP类问题：所有非确定性多项式时间可解的判定问题构成NP类问题。比如在正整数集合中找到下一个质数。求解这个问题是不可以按部就班的解出来的，只能够靠猜或者是线性搜索。然而，验证一个数是否是质数是一个P问题。因此我们就有了下一个定义<br>NP-C问题：NP中的某些问题的复杂性与整个类的复杂性相关联。这些问题中任何一个如果存在多项式时间的算法，那么所有的问题都是多项式时间可解的。这些问题被称为NP-Complete问题。（即可以转换到一个关联的P问题）<br>人们发现，所有的完全多项式非确定性问题，都可以转换为一类满足性（验证）问题的逻辑运算问题。既然这类问题的所有可能答案都可以在多项时间内计算，人们就猜想，是否这类问题存在一个确定性的算法，可以在多项式时间内直接搜索出正确的答案，也就是所以P = NP这个假设是否成立呢？<br>举个例子，神经网络的optimization就是一个NP问题，我们可以用迭代的gradient descent不断向更优的方向逼近。然后用validation set验证结果的好坏。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.senevan.com/2019/02/08/2019-02-08/" data-id="cklhq789f00054hooacg9de2f" data-title="[东拼西凑] P and NP" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post- 2019-01-19" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/01/19/%202019-01-19/" class="article-date">
  <time class="dt-published" datetime="2019-01-19T13:39:33.000Z" itemprop="datePublished">2019-01-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2019/01/19/%202019-01-19/">[有始无终] A Brief Introduction to Reinforcement Learning</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>（文章背景：19年我本来以为自己MSc的论文要写RL相关的题目，然而后面临时改成了CV相关。那时候询着Dr.Po的邮件看到了UT的RL公开课。看完第一个Introduction视频做的笔记。）<br>Some images or paragraph were cited from CS885 of Waterloo University. Thanks to Prof.Poupart for such an amazing course.</p>
<h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Introduction to Reinfocement Learning</li>
</ul>
<h2 id="Introduction-to-Reinforcement-Learning"><a href="#Introduction-to-Reinforcement-Learning" class="headerlink" title="Introduction to Reinforcement Learning"></a>Introduction to Reinforcement Learning</h2><h3 id="Old-paradigm-vs-New-Paradigm"><a href="#Old-paradigm-vs-New-Paradigm" class="headerlink" title="Old paradigm vs. New Paradigm"></a>Old paradigm vs. New Paradigm</h3><p>In the tradational computer science method, we need to program every action of computer. Because the progressive research of Machine Learning field, we can provide some examples to computer, making it learn to accomplish a task based on examples. That is generally called supervised (machine) learning.<br>However, to let machines learn a task need a lot of examples or data. We could label all of the data but that is so laborious. Alternatively, unsupervised learning or semi-supervised learning is more realistic and smart for huge mount of data. There is another method which neither supervised nor unspuervised, the reinforcement learning.</p>
<h3 id="What-is-Reinforcement-Learning"><a href="#What-is-Reinforcement-Learning" class="headerlink" title="What is Reinforcement Learning?"></a>What is Reinforcement Learning?</h3><p>Some well-known nickname, AKA  </p>
<ul>
<li>Optimal control</li>
<li>Approximate dynamic programming</li>
<li>Neuro-dynamic programming  </li>
</ul>
<p>Here is the definition from Wikipedia, you can read this paragrahph for a general view.<br>Reinforcement learning is an area of machine learning inspired by behavioural psychology, concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward.<br>Just like the artifical neural network borrowed the concept of neuron. The reiforcement learning is alsor inspired from creatures.<br>If you want to train a dog to do some specific reactions, you need to reward it when the dog did the correct reactions, for example pleasure and food. On the opposite, some negative reward should be applied when the dog did bad. That is the basic idea to do reforcement for training a dog. If we do the similar things to a machine, that is so called reiforcement learning!  </p>
<h3 id="The-components-in-Reiforcement-Learning-Problem"><a href="#The-components-in-Reiforcement-Learning-Problem" class="headerlink" title="The components in Reiforcement Learning Problem"></a>The components in Reiforcement Learning Problem</h3><p>We need to train an agent instead of a dog for a general reinforcement learning task. So the first component should be the Agent. Except the agent, the all of other things are enviorment of the agent. The agent can change the state of environment by actions, then the environment feedback reward to agent, which is what a reinforcenemt learning system do.<br><a data-flickr-embed="true"  target="_blank" rel="noopener" href="https://www.flickr.com/photos/166826763@N02/46164422064/in/dateposted-public/" title="reiforcement learning"><img src="https://farm8.staticflickr.com/7811/46164422064_6006329497_b.jpg" width="1024" height="611" alt="reiforcement learning"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>
<h3 id="Is-there-any-examples-of-RL"><a href="#Is-there-any-examples-of-RL" class="headerlink" title="Is there any examples of RL"></a>Is there any examples of RL</h3><p>Sure. You may know the famous system developed by DeepMind, the AlphaGO is totally benefited by reinforcement learning. If you are a video game fans you may know there is a competition for traininig an AI to battle with Starcraft. Here I list few task examples which applied or could apply reinforcement learning.</p>
<ul>
<li><p>Game Playing(Go, atari, Starcraft)</p>
</li>
<li><p>Operations research(pricing, veichle routing)</p>
</li>
<li><p>Elevator control</p>
</li>
<li><p>Motor balance control (RL instead of PID I think?)</p>
</li>
<li><p>Spoken dialog systems</p>
</li>
<li><p>Data center energy optimization (some company do this by RL and the result is pretty good)</p>
</li>
<li><p>Self-managing network systems</p>
</li>
<li><p>Autonomous Vehicles (I think it is not a good idea for autonomous car… maybe other vehicle)</p>
</li>
<li><p>Computation Finance (My research topics currently)  </p>
<p>I would like to write more about the RL in Computational Finance.<br>In an automated trading system.</p>
</li>
<li><p>Agent: Trading software(trading bot)</p>
</li>
<li><p>Environment: other traders and the market</p>
</li>
<li><p>State: Price history and current price</p>
</li>
<li><p>Action: basic stock actions, buy/sell/hold etc</p>
</li>
<li><p>Reward: The Profit. Money.  </p>
</li>
</ul>
<p>Definitely we want to maximize our PROFIT.</p>
<h3 id="Overview-of-the-RL"><a href="#Overview-of-the-RL" class="headerlink" title="Overview of the RL"></a>Overview of the RL</h3><p><b>Comprehensive, but challenging form of machine learning.</b>  </p>
<ul>
<li><p>Stochastic environment</p>
</li>
<li><p>Incomplete model (hardly to model but easy to behave by human)</p>
</li>
<li><p>Interdependent sequence if decision.</p>
</li>
<li><p>No supervision</p>
</li>
<li><p>Partial and delayed feedback (Some lag exists)  </p>
<p><b>- Long term goal: lifelong machine learning</b><br>Thank you for reading.</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h3><p><a target="_blank" rel="noopener" href="https://cs.uwaterloo.ca/~ppoupart/teaching/cs885-spring18/schedule.html">https://cs.uwaterloo.ca/~ppoupart/teaching/cs885-spring18/schedule.html</a></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.senevan.com/2019/01/19/%202019-01-19/" data-id="cklhq789c00044hoo803r0dds" data-title="[有始无终] A Brief Introduction to Reinforcement Learning" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; 上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/02/02/2021-02-02/">[C++]实现std::move和std::forward</a>
          </li>
        
          <li>
            <a href="/2021/01/05/2021-01-02/">[南来北往]京沪卧铺动车乘坐体验</a>
          </li>
        
          <li>
            <a href="/2021/01/05/2020-01-01/">[最近的日常]2020年末装机杂记</a>
          </li>
        
          <li>
            <a href="/2020/11/23/2020-11-24/">[我的推荐列表]动画推荐列表</a>
          </li>
        
          <li>
            <a href="/2020/11/22/2020-11-23/">[文章备份][转载]如何排解政治性抑郁</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 Komoriii<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/About-Me" class="mobile-nav-link">About</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>